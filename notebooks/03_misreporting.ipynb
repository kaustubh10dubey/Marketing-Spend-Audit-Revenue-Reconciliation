{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing Misreporting and Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to identify several types of misreporting and anomalies in the marketing and revenue data. We will analyze:\n",
    "1. **Revenue Inflation**: Marketing revenue significantly higher than finance revenue.\n",
    "2. **Missing Invoices**: Revenue reported by marketing but not by finance.\n",
    "3. **Duplicate Attribution**: The same user being attributed to multiple revenue events.\n",
    "4. **Attribution Leakage**: Users who click/engage but do not convert.\n",
    "5. **Outlier Spend Days**: Days with unusually high marketing spend.\n",
    "\n",
    "We will then visualize these anomalies in a Plotly dashboard and assign severity flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "spend_df = pd.read_csv('../data/marketing_spend.csv')\n",
    "events_df = pd.read_csv('../data/funnel_events.csv')\n",
    "revenue_marketing_df = pd.read_csv('../data/revenue_marketing.csv')\n",
    "revenue_finance_df = pd.read_csv('../data/revenue_finance.csv')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "spend_df['date'] = pd.to_datetime(spend_df['date'])\n",
    "events_df['timestamp'] = pd.to_datetime(events_df['timestamp'])\n",
    "revenue_marketing_df['date'] = pd.to_datetime(revenue_marketing_df['date'])\n",
    "revenue_finance_df['date'] = pd.to_datetime(revenue_finance_df['date'])\n",
    "\n",
    "print('Data Loaded and Prepared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detect Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Revenue Inflation (>20% Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_revenue_agg = revenue_marketing_df.groupby('date')['revenue'].sum().reset_index().rename(columns={'revenue': 'mkt_revenue'})\n",
    "fin_revenue_agg = revenue_finance_df.groupby('date')['revenue'].sum().reset_index().rename(columns={'revenue': 'fin_revenue'})\n",
    "\n",
    "revenue_comp = pd.merge(mkt_revenue_agg, fin_revenue_agg, on='date', how='outer').fillna(0)\n",
    "revenue_comp['variance'] = (revenue_comp['mkt_revenue'] - revenue_comp['fin_revenue']) / revenue_comp['fin_revenue']\n",
    "\n",
    "inflated_revenue = revenue_comp[revenue_comp['variance'] > 0.2].copy()\n",
    "inflated_revenue['anomaly_type'] = 'Revenue Inflation'\n",
    "inflated_revenue['severity'] = 'High'\n",
    "inflated_revenue.loc[inflated_revenue['variance'] > 0.5, 'severity'] = 'Critical'\n",
    "\n",
    "print('Revenue Inflation Detection Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Missing Invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_invoices = revenue_comp[revenue_comp['fin_revenue'] == 0].copy()\n",
    "missing_invoices['anomaly_type'] = 'Missing Invoice'\n",
    "missing_invoices['severity'] = 'High'\n",
    "\n",
    "print('Missing Invoice Detection Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Duplicate Attribution\n",
    "**Assumption**: To detect this, we need to link users to revenue. We will merge `events_df` with `revenue_marketing_df` assuming a revenue event happens on the same day as a 'checkout' event for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df['date'] = events_df['timestamp'].dt.date\n",
    "events_df['date'] = pd.to_datetime(events_df['date'])\n",
    "checkout_events = events_df[events_df['event_type'] == 'checkout']\n",
    "user_revenue = pd.merge(checkout_events, revenue_marketing_df, on='date')\n",
    "duplicate_attribution = user_revenue.groupby('user_id').filter(lambda x: len(x) > 1).copy()\n",
    "duplicate_attribution['anomaly_type'] = 'Duplicate Attribution'\n",
    "duplicate_attribution['severity'] = 'Medium'\n",
    "\n",
    "print('Duplicate Attribution Detection Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Attribution Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_users = user_revenue['user_id'].unique()\n",
    "leaked_users = events_df[~events_df['user_id'].isin(converted_users)]\n",
    "attribution_leakage = leaked_users[leaked_users['event_type'] == 'add_to_cart'].copy()\n",
    "attribution_leakage = attribution_leakage.drop_duplicates(subset=['user_id'])\n",
    "attribution_leakage['anomaly_type'] = 'Attribution Leakage'\n",
    "attribution_leakage['severity'] = 'Medium'\n",
    "\n",
    "print('Attribution Leakage Detection Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Outlier Spend Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_mean = spend_df['spend'].mean()\n",
    "spend_std = spend_df['spend'].std()\n",
    "outlier_threshold = spend_mean + 2 * spend_std\n",
    "\n",
    "outlier_spend = spend_df[spend_df['spend'] > outlier_threshold].copy()\n",
    "outlier_spend['anomaly_type'] = 'Outlier Spend'\n",
    "outlier_spend['severity'] = 'High'\n",
    "\n",
    "print('Outlier Spend Detection Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomaly Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Revenue Inflation (>20%)', 'Outlier Spend Days',\n",
    "        'Missing Invoices', 'Duplicate Attributions',\n",
    "        'Attribution Leakage'\n",
    "    ),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'scatter'}],\n",
    "           [{'type': 'table'}, {'type': 'bar'}],\n",
    "           [{'type': 'table'}, {}]]\n",
    ")\n",
    "\n",
    "# Revenue Inflation\n",
    "fig.add_trace(go.Bar(x=inflated_revenue['date'], y=inflated_revenue['variance'], name='Variance', marker_color='red'), row=1, col=1)\n",
    "\n",
    "# Outlier Spend\n",
    "fig.add_trace(go.Scatter(x=spend_df['date'], y=spend_df['spend'], mode='lines', name='Spend'), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=outlier_spend['date'], y=outlier_spend['spend'], mode='markers', name='Outlier', marker=dict(color='red', size=10)), row=1, col=2)\n",
    "\n",
    "# Missing Invoices\n",
    "fig.add_trace(go.Table (\n",
    "    header=dict(values=['Date', 'Marketing Revenue', 'Severity']),\n",
    "    cells=dict(values=[missing_invoices['date'], missing_invoices['mkt_revenue'], missing_invoices['severity']])\n",
    "    ),\n",
    "row=2, col=1)\n",
    "\n",
    "# Duplicate Attributions\n",
    "dup_counts = duplicate_attribution['user_id'].value_counts()\n",
    "fig.add_trace(go.Bar(x=dup_counts.index, y=dup_counts.values, name='Duplicate Count', marker_color='orange'), row=2, col=2)\n",
    "\n",
    "# Attribution Leakage\n",
    "fig.add_trace(go.Table(\n",
    "    header=dict(values=['User ID', 'Last Event Time', 'Severity']),\n",
    "    cells=dict(values=[attribution_leakage['user_id'], attribution_leakage['timestamp'], attribution_leakage['severity']])\n",
    "    ),\n",
    "row=3, col=1)\n",
    "\n",
    "fig.update_layout(height=1200, title_text='Marketing Anomaly Dashboard', showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
